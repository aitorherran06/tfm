import os
from datetime import datetime

import streamlit as st
import pandas as pd
import altair as alt
from pymongo import MongoClient
import geopandas as gpd  # Para Copernicus (m√°s adelante)

# =========================================================
# CONFIGURACI√ìN DE P√ÅGINA
# =========================================================
st.set_page_config(
    page_title="Datos del proyecto ‚Äì Incendios Espa√±a",
    layout="wide",
)

st.title("üìö Datos del proyecto")
st.markdown(
    """
Esta p√°gina resume los distintos datasets usados en el proyecto y permite
explorar r√°pidamente la informaci√≥n de cada fuente:

- üõ∞Ô∏è **FIRMS** (detecciones satelitales hist√≥ricas)  
- üî• **Copernicus EFFIS** (severidad y √°rea quemada)  
- üå¶Ô∏è **Open-Meteo** (meteorolog√≠a hist√≥rica)  
- ‚è±Ô∏è **Datos operativos generados por _cronjobs_ (AEMET + FIRMS actualizado)**  
- üîÑ **Equivalencias de variables entre datasets**  
"""
)

# =========================================================
# TABS PRINCIPALES
# =========================================================
(
    tab_firms,
    tab_cop,
    tab_openmeteo,
    tab_cronjobs,
    tab_equiv,
) = st.tabs(
    [
        "üõ∞Ô∏è FIRMS",
        "üî• Copernicus EFFIS",
        "üå¶Ô∏è Open-Meteo hist√≥rico",
        "‚è±Ô∏è Datos cronjobs",
        "üîÑ Equivalencias",
    ]
)

# =========================================================
# CARGA FIRMS DESDE MONGO (FUENTE √öNICA)
# =========================================================
@st.cache_data(show_spinner=True)
def load_firms_from_mongo() -> pd.DataFrame:
    """
    Carga el hist√≥rico FIRMS desde MongoDB.
    Colecci√≥n esperada: incendios_espana.firms_historico
    """

    client = MongoClient(st.secrets["MONGO"]["URI"])
    db = client["incendios_espana"]
    col = db["firms_historico"]

    docs = list(col.find({}, {"_id": 0}))
    df = pd.DataFrame(docs)

    if df.empty:
        return df

    # Tipos y limpieza m√≠nima
    df["firms_date"] = pd.to_datetime(df["firms_date"], errors="coerce")
    df["provincia"] = df["provincia"].astype(str).str.strip()

    return df


# =========================================================
# 1) TAB FIRMS
# =========================================================
with tab_firms:
    st.header("üõ∞Ô∏è FIRMS ‚Äì Detecciones hist√≥ricas de incendios")

    try:
        df_firms_full = load_firms_from_mongo()
    except Exception as e:
        st.error(f"‚ùå No se pudo cargar FIRMS desde MongoDB: {e}")
        st.stop()

    st.success(f"Registros FIRMS: **{len(df_firms_full):,}**")

    if df_firms_full["firms_date"].notna().any():
        min_date_global = df_firms_full["firms_date"].min()
        max_date_global = df_firms_full["firms_date"].max()
        st.caption(
            f"üóìÔ∏è Periodo disponible FIRMS: "
            f"**{min_date_global:%d/%m/%Y} ‚Äì {max_date_global:%d/%m/%Y}**"
        )
    else:
        st.caption("üóìÔ∏è Periodo disponible FIRMS: no hay fechas v√°lidas.")

    # ---------- Filtros SOLO para FIRMS ----------
    st.markdown("### üîç Filtros FIRMS")

    df_firms = df_firms_full.copy()

    col_f1, col_f2 = st.columns(2)

    # Filtro por fechas
    with col_f1:
        if min_date_global and max_date_global:
            date_min = min_date_global.date()
            date_max = max_date_global.date()
            date_range = st.date_input(
                "Rango de fechas",
                value=(date_min, date_max),
                min_value=date_min,
                max_value=date_max,
            )

            if isinstance(date_range, tuple) and len(date_range) == 2:
                dmin, dmax = date_range
                mask_date = (
                    (df_firms["firms_date"].dt.date >= dmin)
                    & (df_firms["firms_date"].dt.date <= dmax)
                )
                df_firms = df_firms[mask_date]
        else:
            st.caption("No se puede filtrar por fecha (no hay fechas v√°lidas).")



    st.markdown(
        f"üìÅ **Registros mostrados en esta vista (con filtros):** {len(df_firms):,}"
    )

    # ---------- Explicaci√≥n de columnas ----------
    with st.expander("‚ÑπÔ∏è ¬øQu√© significan las columnas principales de FIRMS?"):
        st.markdown(
            """
- **latitude / longitude / firms_latitude / firms_longitude**: posici√≥n geogr√°fica exacta de la detecci√≥n.  
- **firms_date / acq_date + acq_time**: fecha (y hora) en la que el sat√©lite detecta el punto caliente.  
- **brightness / firms_brightness**: temperatura aparente del fuego (Kelvin); a mayor valor, mayor intensidad t√©rmica.  
- **frp / firms_frp**: _Fire Radiative Power_ (MW), una medida de la energ√≠a radiada por el fuego.  
- **provincia**: provincia espa√±ola asignada a la detecci√≥n tras el cruce espacial.  
"""
        )

    # ---------- Muestra de datos ----------
    st.subheader("üìã Muestra de datos FIRMS (con filtros aplicados)")
    possible_cols = [
        "firms_date",
        "provincia",
        "latitude",
        "longitude",
        "firms_latitude",
        "firms_longitude",
        "brightness",
        "firms_brightness",
        "frp",
        "firms_frp",
    ]
    sample_cols = [c for c in possible_cols if c in df_firms.columns]
    st.dataframe(df_firms[sample_cols].head(20), use_container_width=True)

    # ---------- KPIs sobre la vista filtrada ----------
    st.subheader("üìä Indicadores b√°sicos (vista filtrada)")
    c1, c3, c4 = st.columns(3)

    c1.metric("N¬∫ detecciones", f"{len(df_firms):,}")

    brightness_col = (
        "firms_brightness"
        if "firms_brightness" in df_firms.columns
        else "brightness"
        if "brightness" in df_firms.columns
        else None
    )
    if brightness_col:
        c3.metric("Brightness medio", f"{df_firms[brightness_col].mean():.1f}")
    else:
        c3.metric("Brightness medio", "N/D")

    frp_col = (
        "firms_frp"
        if "firms_frp" in df_firms.columns
        else "frp"
        if "frp" in df_firms.columns
        else None
    )
    if frp_col:
        c4.metric("FRP medio (MW)", f"{df_firms[frp_col].mean():.2f}")
    else:
        c4.metric("FRP medio (MW)", "N/D")


    # ---------- Serie anual (vista filtrada) ----------
    st.subheader("üìà Evoluci√≥n anual del n√∫mero de detecciones (vista filtrada)")
    if df_firms["firms_date"].notna().any():
        df_firms["year"] = df_firms["firms_date"].dt.year
        count_col = brightness_col or "firms_date"
        yearly = (
            df_firms.groupby("year", as_index=False)
            .agg(n_fires=(count_col, "count"))
            .sort_values("year")
        )

        chart_year = (
            alt.Chart(yearly)
            .mark_bar()
            .encode(
                x=alt.X("year:O", title="A√±o"),
                y=alt.Y("n_fires:Q", title="N¬∫ detecciones FIRMS"),
                tooltip=["year:O", "n_fires:Q"],
            )
            .properties(height=300)
        )
        st.altair_chart(chart_year, use_container_width=True)
    else:
        st.info("No hay fechas v√°lidas para construir la serie anual.")

# =========================================================
# 2) TAB COPERNICUS EFFIS (shapefile en carpeta copernicus)
# =========================================================
with tab_cop:
    st.header("üî• Copernicus EFFIS ‚Äì Severidad y √°rea quemada")

    st.markdown(
        """
Copernicus **EFFIS** (European Forest Fire Information System) proporciona 
los **per√≠metros oficiales de incendios** en Europa.  
En este dataset, **cada fila representa un pol√≠gono de √°rea quemada**, con atributos 
sobre su extensi√≥n, fecha y localizaci√≥n administrativa.
"""
    )

    @st.cache_data(show_spinner=True)
    def load_copernicus(path: str) -> gpd.GeoDataFrame:
        gdf_ = gpd.read_file(path)
        return gdf_

    try:
        gdf_effis = load_copernicus(COPERNICUS_SHP)
    #    st.caption(f"üìÇ Shapefile cargado: `{COPERNICUS_SHP}`")
        st.success(f"Pol√≠gonos quemados: **{len(gdf_effis):,}**")
    except Exception as e:
        st.error(f"‚ùå No se pudo cargar Copernicus EFFIS: {e}")
        st.stop()

    # Rango temporal: intentamos detectar columna de fecha o de a√±o
    date_cols = [c for c in gdf_effis.columns if "date" in c.lower()]
    year_cols = [c for c in gdf_effis.columns if "year" in c.lower()]

    rango_str = None
    if date_cols:
        col = date_cols[0]
        gdf_effis[col] = pd.to_datetime(gdf_effis[col], errors="coerce")
        if gdf_effis[col].notna().any():
            min_d = gdf_effis[col].min()
            max_d = gdf_effis[col].max()
            rango_str = f"{min_d:%d/%m/%Y} ‚Äì {max_d:%d/%m/%Y}"
    elif year_cols:
        col = year_cols[0]
        min_y = gdf_effis[col].min()
        max_y = gdf_effis[col].max()
        rango_str = f"{int(min_y)} ‚Äì {int(max_y)}"

    if rango_str:
        st.caption(f"üóìÔ∏è Periodo disponible Copernicus EFFIS: **{rango_str}**")
    else:
        st.caption(
            "üóìÔ∏è Periodo disponible Copernicus EFFIS: no se ha encontrado columna de fecha/a√±o."
        )

    # Explicaci√≥n de columnas
    with st.expander("‚ÑπÔ∏è ¬øQu√© significan las columnas principales de EFFIS?"):
        st.markdown(
            """
Aunque los nombres pueden variar seg√∫n la versi√≥n del shapefile, normalmente encontrar√°s:

- **geometry**: pol√≠gono geoespacial que delimita el √°rea quemada.  
- **AREA_HA / BA_HA / BURN_AREA**: superficie quemada en hect√°reas.  
- **YEAR / BA_YEAR / FIRE_YEAR**: a√±o del incendio.  
- **NUTS_ID / NUTS_NAME**: c√≥digo/nombre de la unidad administrativa europea (regi√≥n).  
- **ADM_NAME / provincia / municipio**: nombre de la unidad administrativa (seg√∫n pa√≠s).  

En esta p√°gina nos centramos sobre todo en:
- **el √°rea quemada (ha)** ‚Üí para medir la severidad,  
- **las columnas de tipo texto** ‚Üí para agrupar por regi√≥n, provincia, etc.
"""
        )

    st.subheader("üìã Muestra de datos EFFIS (atributos no geom√©tricos)")
    attrs = gdf_effis.drop(columns=["geometry"], errors="ignore")
    st.dataframe(attrs.head(20), use_container_width=True)

    # Detectar columna de √°rea en hect√°reas
    area_candidates = [
        c for c in attrs.columns if "area" in c.lower() and "ha" in c.lower()
    ]
    if not area_candidates:
        for cand in ["AREA_HA", "BA_HA", "BURN_AREA", "BAAREA"]:
            if cand in attrs.columns:
                area_candidates = [cand]
                break
    area_col = area_candidates[0] if area_candidates else None

    # M√©tricas b√°sicas
    c1, c2 = st.columns(2)
    if area_col:
        area_numeric = pd.to_numeric(attrs[area_col], errors="coerce")
        area_total = area_numeric.sum()
        c1.metric("√Årea total quemada (ha)", f"{area_total:,.1f}")
    else:
        c1.metric("√Årea total quemada (ha)", "N/D")

    c2.metric("N√∫mero de pol√≠gonos", f"{len(attrs):,}")

    # Ranking por entidad
    st.subheader("üèÖ Entidades con mayor √°rea quemada (Copernicus)")

    if area_col:
        cat_cols = attrs.select_dtypes(include="object").columns.tolist()

        if cat_cols:
            candidatos_nombre = [
                "NAME",
                "name",
                "NUTS_NAME",
                "NUTS_ID",
                "ADM_NAME",
                "provincia",
                "municipio",
            ]
            default_col = None
            for cand in candidatos_nombre:
                if cand in cat_cols:
                    default_col = cand
                    break
            if default_col is None:
                default_col = cat_cols[0]

            group_col = st.selectbox(
                "Agrupar por:",
                options=cat_cols,
                index=cat_cols.index(default_col),
                help="Columna categ√≥rica usada para agrupar el √°rea quemada.",
            )

            area_numeric = pd.to_numeric(attrs[area_col], errors="coerce")

            ranking = (
                attrs.assign(_area=area_numeric)
                .groupby(group_col, as_index=False)
                .agg(area_total=("_area", "sum"))
                .sort_values("area_total", ascending=False)
            )

            chart_rank = (
                alt.Chart(ranking.head(15))
                .mark_bar()
                .encode(
                    x=alt.X("area_total:Q", title="√Årea quemada total (ha)"),
                    y=alt.Y(f"{group_col}:N", sort="-x", title=group_col),
                    tooltip=[group_col, "area_total"],
                )
                .properties(height=400)
            )
            st.altair_chart(chart_rank, use_container_width=True)
        else:
            st.info(
                "No se han encontrado columnas de texto para agrupar (nombre de provincia, NUTS, etc.)."
            )
    else:
        st.info(
            "No se ha identificado una columna de √°rea en hect√°reas, por lo que no se puede construir el ranking."
        )

# =========================================================
# 3) TAB OPEN-METEO HIST√ìRICO (openmeteo_historico.csv)
# =========================================================
with tab_openmeteo:
    st.header("üå¶Ô∏è Open-Meteo ‚Äì Meteorolog√≠a hist√≥rica")

    st.markdown(
        """
Open-Meteo proporciona **series hist√≥ricas de meteorolog√≠a** a partir de coordenadas.  
En este dataset, los datos ya est√°n **agregados por provincia y d√≠a**, 
de forma que cada fila representa el clima diario de una provincia.
"""
    )

    @st.cache_data(show_spinner=True)
    def load_openmeteo(path: str) -> pd.DataFrame:
        # Leemos usando la columna 'time' como fecha
        df_ = pd.read_csv(path, parse_dates=["time"])

        # Renombramos a los nombres que usa el resto del panel
        df_ = df_.rename(
            columns={
                "time": "date",
                "temperature_2m_max": "meteo_temp_max",
                "temperature_2m_min": "meteo_temp_min",
                "relative_humidity_2m_min": "meteo_humidity_min",
                "windspeed_10m_max": "meteo_wind_max",
            }
        )
        return df_

    try:
        df_met = load_openmeteo(OPENMETEO_CSV)
    #    st.caption(f"üìÇ Archivo cargado: `{OPENMETEO_CSV}`")
        st.success(f"Registros provincia‚Äìd√≠a: **{len(df_met):,}**")

        if df_met["date"].notna().any():
            min_date_met = df_met["date"].min()
            max_date_met = df_met["date"].max()
            st.caption(
                f"üóìÔ∏è Periodo disponible Open-Meteo: "
                f"**{min_date_met:%d/%m/%Y} ‚Äì {max_date_met:%d/%m/%Y}**"
            )
        else:
            st.caption("üóìÔ∏è Periodo disponible Open-Meteo: no hay fechas v√°lidas.")
    except Exception as e:
        st.error(f"‚ùå No se pudo cargar Open-Meteo: {e}")
        st.stop()

    with st.expander("‚ÑπÔ∏è ¬øQu√© significan las columnas de Open-Meteo?"):
        st.markdown(
            """
- **date**: d√≠a al que corresponde la predicci√≥n/observaci√≥n.  
- **provincia**: provincia asociada a las coordenadas usadas.  
- **meteo_temp_max / meteo_temp_min**: temperatura m√°xima y m√≠nima diarias (¬∞C).  
- **meteo_humidity_min**: humedad relativa m√≠nima del d√≠a (%); valores bajos indican sequedad.  
- **meteo_wind_max**: velocidad m√°xima del viento (10 m) durante el d√≠a.  
"""
        )

    st.subheader("üìã Muestra de datos meteorol√≥gicos")
    cols_met_sample = [
        "date",
        "provincia",
        "meteo_temp_max",
        "meteo_temp_min",
        "meteo_humidity_min",
        "meteo_wind_max",
    ]
    cols_met_sample = [c for c in cols_met_sample if c in df_met.columns]
    st.dataframe(df_met[cols_met_sample].head(20), use_container_width=True)

    c1, c2, c3, c4 = st.columns(4)
    if "meteo_temp_max" in df_met.columns:
        c1.metric("Temp. m√°xima media", f"{df_met['meteo_temp_max'].mean():.1f} ¬∞C")
    else:
        c1.metric("Temp. m√°xima media", "N/D")

    if "meteo_temp_min" in df_met.columns:
        c2.metric("Temp. m√≠nima media", f"{df_met['meteo_temp_min'].mean():.1f} ¬∞C")
    else:
        c2.metric("Temp. m√≠nima media", "N/D")

    if "meteo_humidity_min" in df_met.columns:
        c3.metric(
            "Humedad m√≠nima media", f"{df_met['meteo_humidity_min'].mean():.1f} %"
        )
    else:
        c3.metric("Humedad m√≠nima media", "N/D")

    if "meteo_wind_max" in df_met.columns:
        c4.metric("Viento m√°x. medio", f"{df_met['meteo_wind_max'].mean():.1f} km/h")
    else:
        c4.metric("Viento m√°x. medio", "N/D")

    # Temperatura m√°xima media por mes
    if "meteo_temp_max" in df_met.columns:
        st.subheader("üìà Temperatura m√°xima media por mes (promedio de todos los a√±os)")

        df_met["month"] = df_met["date"].dt.month
        df_met["month_name"] = df_met["date"].dt.strftime("%b")

        monthly = (
            df_met.groupby(["month", "month_name"], as_index=False)
            .agg(temp_max_mean=("meteo_temp_max", "mean"))
            .sort_values("month")
        )

        chart_month = (
            alt.Chart(monthly)
            .mark_line(point=True)
            .encode(
                x=alt.X(
                    "month_name:N",
                    title="Mes",
                    sort=[
                        "Jan",
                        "Feb",
                        "Mar",
                        "Apr",
                        "May",
                        "Jun",
                        "Jul",
                        "Aug",
                        "Sep",
                        "Oct",
                        "Nov",
                        "Dec",
                    ],
                ),
                y=alt.Y("temp_max_mean:Q", title="Temp. m√°xima media (¬∞C)"),
                tooltip=[
                    alt.Tooltip("month_name:N", title="Mes"),
                    alt.Tooltip(
                        "temp_max_mean:Q", title="Temp. media m√°x.", format=".1f"
                    ),
                ],
            )
            .properties(height=300)
            .interactive()
        )

        st.altair_chart(chart_month, use_container_width=True)

        st.markdown("---")

        # Temperatura m√°xima media por a√±o
        st.subheader("üìà Temperatura m√°xima media por a√±o")

        df_met["year"] = df_met["date"].dt.year

        yearly_temp = (
            df_met.groupby("year", as_index=False)
            .agg(temp_max_mean=("meteo_temp_max", "mean"))
            .sort_values("year")
        )

        chart_year_temp = (
            alt.Chart(yearly_temp)
            .mark_line(point=True)
            .encode(
                x=alt.X("year:O", title="A√±o"),
                y=alt.Y("temp_max_mean:Q", title="Temp. m√°xima media (¬∞C)"),
                tooltip=[
                    alt.Tooltip("year:O", title="A√±o"),
                    alt.Tooltip(
                        "temp_max_mean:Q", title="Temp. media m√°x.", format=".1f"
                    ),
                ],
            )
            .properties(height=300)
            .interactive()
        )
        st.altair_chart(chart_year_temp, use_container_width=True)
    else:
        st.info(
            "La columna 'meteo_temp_max' no est√° disponible; no se generan las series de temperatura."
        )

# =========================================================
# 4) TAB DATOS CRONJOBS (AEMET + FIRMS actualizado)
# =========================================================
with tab_cronjobs:
    st.header("‚è±Ô∏è Datos operativos generados por cronjobs")
    st.markdown(
        """
Esta secci√≥n resume los **datasets operativos** que se actualizan autom√°ticamente 
mediante _cronjobs_ y alimentan:

- el panel de **puntos calientes FIRMS recientes**, y  
- el panel de **predicci√≥n de riesgo a partir de AEMET**.
"""
    )

    # Conexi√≥n a Mongo
    try:
        mongo_uri = st.secrets["MONGO"]["URI"]
        client = MongoClient(mongo_uri)
        db = client["incendios_espana"]
    except Exception as e:
        db = None
        st.error(f"‚ùå No se pudo conectar a MongoDB (revisa `MONGO.URI`): {e}")

    if db is not None:
        # ---------- AEMET PREDICCIONES ----------
        st.subheader("üå¶Ô∏è Colecci√≥n `aemet_predicciones`")
        st.markdown(
            """
Contiene las **predicciones meteorol√≥gicas oficiales de AEMET** para los pr√≥ximos d√≠as
en cada provincia. Se genera diariamente mediante un proceso autom√°tico.
"""
        )

        col_aemet = db["aemet_predicciones"]
        count_aemet = col_aemet.count_documents({})
        st.write(f"üìÑ **Documentos totales:** {count_aemet}")

        # Rango de fechas AEMET
        try:
            doc_min_aemet = col_aemet.find_one(sort=[("fecha", 1)])
            doc_max_aemet = col_aemet.find_one(sort=[("fecha", -1)])
            if doc_min_aemet and doc_max_aemet:
                st.caption(
                    f"üóìÔ∏è Periodo disponible AEMET: "
                    f"**{doc_min_aemet.get('fecha')} ‚Äì {doc_max_aemet.get('fecha')}**"
                )
        except Exception:
            st.caption("üóìÔ∏è Periodo disponible AEMET: no se pudo calcular.")

        docs_aemet = list(col_aemet.find({}, {"_id": 0}).limit(20))

        filas = []
        for d in docs_aemet:
            temp = d.get("temperatura", {}) or {}
            hum = d.get("humedadRelativa", {}) or {}

            fila = {
                "provincia": d.get("provincia"),
                "fecha": d.get("fecha"),
                "tmax": temp.get("maxima"),
                "tmin": temp.get("minima"),
                "humedad_max": hum.get("maxima"),
                "humedad_min": hum.get("minima"),
                "uvMax": d.get("uvMax"),
            }
            filas.append(fila)

        if filas:
            df_aemet_sample = pd.DataFrame(filas)
            df_aemet_sample["fecha"] = pd.to_datetime(
                df_aemet_sample["fecha"], errors="coerce"
            )
            st.dataframe(df_aemet_sample, use_container_width=True)
        else:
            st.info("No hay documentos que mostrar en la muestra.")

        st.markdown("---")

        # ---------- FIRMS ACTUALIZADO ----------
        st.subheader("üî• Colecci√≥n `firms_actualizado`")
        st.markdown(
            """
Contiene las **detecciones FIRMS m√°s recientes** (√∫ltimos d√≠as) ya filtradas a Espa√±a.  
Se actualiza autom√°ticamente cada pocas horas mediante un _cronjob_.
"""
        )

        col_firms = db["firms_actualizado"]
        count_firms = col_firms.count_documents({})
        st.write(f"üìÑ **Documentos totales:** {count_firms}")

        # Rango de fechas FIRMS actualizado
        try:
            doc_min_firms = col_firms.find_one(
                {"fecha": {"$exists": True}}, sort=[("fecha", 1)]
            ) or col_firms.find_one(sort=[("datetime", 1)])

            doc_max_firms = col_firms.find_one(
                {"fecha": {"$exists": True}}, sort=[("fecha", -1)]
            ) or col_firms.find_one(sort=[("datetime", -1)])

            if doc_min_firms and doc_max_firms:
                vmin = doc_min_firms.get("fecha") or doc_min_firms.get("datetime")
                vmax = doc_max_firms.get("fecha") or doc_max_firms.get("datetime")
                st.caption(
                    f"üóìÔ∏è Periodo disponible FIRMS actualizado: **{vmin} ‚Äì {vmax}**"
                )
        except Exception:
            st.caption(
                "üóìÔ∏è Periodo disponible FIRMS actualizado: no se pudo calcular."
            )

        docs_firms = list(col_firms.find({}, {"_id": 0}).limit(20))

        if docs_firms:
            df_firms_sample = pd.DataFrame(docs_firms)
            st.dataframe(df_firms_sample, use_container_width=True)
        else:
            st.info("No hay documentos que mostrar en la muestra.")

    st.success("‚úÖ Informaci√≥n de cronjobs mostrada correctamente.")

# =========================================================
# 5) TAB EQUIVALENCIAS
# =========================================================
with tab_equiv:
    st.header("üîÑ Equivalencias de variables entre datasets")
    st.markdown(
        """
Esta secci√≥n muestra c√≥mo se corresponden las columnas entre distintas fuentes, 
lo que permite **unificar los datos** para an√°lisis y modelado.
"""
    )

    tab1, tab2 = st.tabs(["üõ∞Ô∏è FIRMS Hist√≥rico ‚Üî Actualizado", "üå¶Ô∏è AEMET ‚Üî Open-Meteo"])

    # -----------------------------------------------------
    #   TAB 1 : FIRMS
    # -----------------------------------------------------
    with tab1:
        st.header("üõ∞Ô∏è Equivalencias FIRMS ‚Äî Hist√≥rico ‚Üî Actualizado")
        st.markdown(
            """
Los ficheros de FIRMS antiguos y los m√°s recientes usan nombres de columnas distintos, 
aunque representan la misma informaci√≥n.  
Esta tabla resume las equivalencias usadas en el proyecto.
"""
        )

        equivalencias_firms = pd.DataFrame(
            {
                "FIRMS Hist√≥rico": [
                    "latitude",
                    "longitude",
                    "brightness",
                    "scan",
                    "track",
                    "acq_date",
                    "acq_time",
                    "satellite",
                    "instrument",
                ],
                "FIRMS Actualizado": [
                    "latitud",
                    "longitud",
                    "brightness",
                    "scan",
                    "track",
                    "fecha",
                    "hora",
                    "satellite",
                    "confianza",
                ],
                "Descripci√≥n": [
                    "Latitud del punto detectado",
                    "Longitud del punto detectado",
                    "Brillo (temperatura aparente del fuego, Kelvin)",
                    "Tama√±o del p√≠xel en direcci√≥n de escaneo",
                    "Tama√±o del p√≠xel en direcci√≥n de la trayectoria del sat√©lite",
                    "Fecha de adquisici√≥n",
                    "Hora de adquisici√≥n (UTC)",
                    "Sat√©lite utilizado",
                    "Nivel de confianza en la detecci√≥n",
                ],
            }
        )

        st.subheader("üìë Tabla comparativa FIRMS")
        st.dataframe(equivalencias_firms, use_container_width=True)

        st.info(
            """
‚û§ Los datasets contienen la misma informaci√≥n esencial, aunque con ajustes en nombres.  
‚û§ El campo **confianza** aparece en versiones actualizadas.  
"""
        )

        st.subheader("üîÑ Diccionario de renombrado FIRMS")
        diccionario_firms = {
            "latitude": "latitud",
            "longitude": "longitud",
            "acq_date": "fecha",
            "acq_time": "hora",
            "instrument": "instrumento",
        }
        st.code(diccionario_firms, language="python")
        st.caption("Aplicaci√≥n en pandas:")
        st.code("df.rename(columns=diccionario_firms, inplace=True)", language="python")

    # -----------------------------------------------------
    #   TAB 2 : AEMET ‚Üî Open-Meteo
    # -----------------------------------------------------
    with tab2:
        st.header("üå¶Ô∏è Equivalencias entre AEMET y Open-Meteo")
        st.markdown(
            """
AEMET y Open-Meteo describen fen√≥menos meteorol√≥gicos similares, 
pero con **nombres de columnas y estructuras distintas**.  
Esta tabla resume c√≥mo se han alineado en el proyecto.
"""
        )

        equivalencias = pd.DataFrame(
            {
                "AEMET": [
                    "fecha",
                    "municipio",
                    "provincia",
                    "tmax",
                    "tmin",
                    "humedad_max",
                    "humedad_min",
                    "viento",
                    "fuente",
                ],
                "Open-Meteo": [
                    "time",
                    None,
                    "provincia",
                    "temperature_2m_max",
                    "temperature_2m_min",
                    "relative_humidity_2m_max",
                    "relative_humidity_2m_min",
                    "windspeed_10m_max",
                    None,
                ],
                "Descripci√≥n": [
                    "Fecha de observaci√≥n o predicci√≥n",
                    "Municipio o estaci√≥n meteorol√≥gica",
                    "Provincia o regi√≥n administrativa",
                    "Temperatura m√°xima diaria (¬∞C)",
                    "Temperatura m√≠nima diaria (¬∞C)",
                    "Humedad relativa m√°xima (%)",
                    "Humedad relativa m√≠nima (%)",
                    "Velocidad m√°xima del viento",
                    "Fuente de los datos",
                ],
            }
        )

        st.subheader("üìë Tabla comparativa AEMET ‚Üî Open-Meteo")
        st.dataframe(equivalencias, use_container_width=True)

        st.info(
            """
‚û§ Open-Meteo usa coordenadas (lat/lon) en lugar de municipios.  
‚û§ Incluye m√°s variables como precipitaci√≥n total o radiaci√≥n solar.  
"""
        )

        st.subheader("üîÑ Diccionario de renombrado AEMET ‚Üí Open-Meteo")
        diccionario_renombrado = {
            "fecha": "time",
            "tmax": "temperature_2m_max",
            "tmin": "temperature_2m_min",
            "humedad_max": "relative_humidity_2m_max",
            "humedad_min": "relative_humidity_2m_min",
            "viento": "windspeed_10m_max",
            "provincia": "provincia",
        }
        st.code(diccionario_renombrado, language="python")
        st.caption("Aplicaci√≥n en pandas:")
        st.code("df.rename(columns=diccionario_renombrado, inplace=True)", language="python")

    st.success("‚úÖ Bloque de equivalencias cargado correctamente.")










