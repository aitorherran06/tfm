import os
from datetime import datetime

import streamlit as st
import pandas as pd
import altair as alt
from pymongo import MongoClient
import geopandas as gpd  
import json
import pydeck as pdk
from shapely.geometry import shape   

# =========================================================
# CONFIGURACI√ìN DE P√ÅGINA
# =========================================================
st.set_page_config(
    page_title="Datos del proyecto ‚Äì Incendios Espa√±a",
    layout="wide",
)

st.title("üìö Datos del proyecto")
st.markdown(
    """
Esta p√°gina resume los distintos datasets usados en el proyecto y permite
explorar r√°pidamente la informaci√≥n de cada fuente:

- üõ∞Ô∏è **FIRMS** (detecciones satelitales hist√≥ricas)  
- üî• **Copernicus EFFIS** (severidad y √°rea quemada)  
- üå¶Ô∏è **Open-Meteo** (meteorolog√≠a hist√≥rica)  
- ‚è±Ô∏è **Datos operativos generados por _cronjobs_ (AEMET + FIRMS actualizado)**  
- üîÑ **Equivalencias de variables entre datasets**  
"""
)

# =========================================================
# TABS PRINCIPALES
# =========================================================
(
    tab_firms,
    tab_cop,
    tab_openmeteo,
    tab_cronjobs,
    tab_equiv,
) = st.tabs(
    [
        "üõ∞Ô∏è FIRMS",
        "üî• Copernicus EFFIS",
        "üå¶Ô∏è Open-Meteo hist√≥rico",
        "‚è±Ô∏è Datos cronjobs",
        "üîÑ Equivalencias",
    ]
)

# =========================================================
# CARGA FIRMS DESDE MONGO (FUENTE √öNICA)
# =========================================================
@st.cache_data(show_spinner=True)
def load_firms_from_mongo() -> pd.DataFrame:
    """
    Carga el hist√≥rico FIRMS desde MongoDB.
    Colecci√≥n esperada: incendios_espana.firms_historico
    """

    client = MongoClient(st.secrets["MONGO"]["URI"])
    db = client["incendios_espana"]
    col = db["firms_historico"]

    docs = list(col.find({}, {"_id": 0}))
    df = pd.DataFrame(docs)

    if df.empty:
        return df

    # Tipos y limpieza m√≠nima
    df["firms_date"] = pd.to_datetime(df["firms_date"], errors="coerce")
    df["provincia"] = df["provincia"].astype(str).str.strip()

    return df


# =========================================================
# 1) TAB FIRMS
# =========================================================
with tab_firms:
    st.header("üõ∞Ô∏è FIRMS ‚Äì Detecciones hist√≥ricas de incendios")

    try:
        df_firms_full = load_firms_from_mongo()
    except Exception as e:
        st.error(f"‚ùå No se pudo cargar FIRMS desde MongoDB: {e}")
        st.stop()

    st.success(f"Registros FIRMS: **{len(df_firms_full):,}**")

    if df_firms_full["firms_date"].notna().any():
        min_date_global = df_firms_full["firms_date"].min()
        max_date_global = df_firms_full["firms_date"].max()
        st.caption(
            f"üóìÔ∏è Periodo disponible FIRMS: "
            f"**{min_date_global:%d/%m/%Y} ‚Äì {max_date_global:%d/%m/%Y}**"
        )
    else:
        st.caption("üóìÔ∏è Periodo disponible FIRMS: no hay fechas v√°lidas.")

    # ---------- Filtros SOLO para FIRMS ----------
    st.markdown("### üîç Filtros FIRMS")

    df_firms = df_firms_full.copy()

    col_f1, col_f2 = st.columns(2)

    # Filtro por fechas
    with col_f1:
        if min_date_global and max_date_global:
            date_min = min_date_global.date()
            date_max = max_date_global.date()
            date_range = st.date_input(
                "Rango de fechas",
                value=(date_min, date_max),
                min_value=date_min,
                max_value=date_max,
            )

            if isinstance(date_range, tuple) and len(date_range) == 2:
                dmin, dmax = date_range
                mask_date = (
                    (df_firms["firms_date"].dt.date >= dmin)
                    & (df_firms["firms_date"].dt.date <= dmax)
                )
                df_firms = df_firms[mask_date]
        else:
            st.caption("No se puede filtrar por fecha (no hay fechas v√°lidas).")



    st.markdown(
        f"üìÅ **Registros mostrados en esta vista (con filtros):** {len(df_firms):,}"
    )

    # ---------- Explicaci√≥n de columnas ----------
    with st.expander("‚ÑπÔ∏è ¬øQu√© significan las columnas principales de FIRMS?"):
        st.markdown(
            """
- **latitude / longitude / firms_latitude / firms_longitude**: posici√≥n geogr√°fica exacta de la detecci√≥n.  
- **firms_date / acq_date + acq_time**: fecha (y hora) en la que el sat√©lite detecta el punto caliente.  
- **brightness / firms_brightness**: temperatura aparente del fuego (Kelvin); a mayor valor, mayor intensidad t√©rmica.  
- **frp / firms_frp**: _Fire Radiative Power_ (MW), una medida de la energ√≠a radiada por el fuego.  
- **provincia**: provincia espa√±ola asignada a la detecci√≥n tras el cruce espacial.  
"""
        )

    # ---------- Muestra de datos ----------
    st.subheader("üìã Muestra de datos FIRMS (con filtros aplicados)")
    possible_cols = [
        "firms_date",
        "provincia",
        "latitude",
        "longitude",
        "firms_latitude",
        "firms_longitude",
        "brightness",
        "firms_brightness",
        "frp",
        "firms_frp",
    ]
    sample_cols = [c for c in possible_cols if c in df_firms.columns]
    st.dataframe(df_firms[sample_cols].head(20), use_container_width=True)

    # ---------- KPIs sobre la vista filtrada ----------
    st.subheader("üìä Indicadores b√°sicos (vista filtrada)")
    c1, c3, c4 = st.columns(3)

    c1.metric("N¬∫ detecciones", f"{len(df_firms):,}")

    brightness_col = (
        "firms_brightness"
        if "firms_brightness" in df_firms.columns
        else "brightness"
        if "brightness" in df_firms.columns
        else None
    )
    if brightness_col:
        c3.metric("Brightness medio", f"{df_firms[brightness_col].mean():.1f}")
    else:
        c3.metric("Brightness medio", "N/D")

    frp_col = (
        "firms_frp"
        if "firms_frp" in df_firms.columns
        else "frp"
        if "frp" in df_firms.columns
        else None
    )
    if frp_col:
        c4.metric("FRP medio (MW)", f"{df_firms[frp_col].mean():.2f}")
    else:
        c4.metric("FRP medio (MW)", "N/D")


    # ---------- Serie anual (vista filtrada) ----------
    st.subheader("üìà Evoluci√≥n anual del n√∫mero de detecciones (vista filtrada)")
    if df_firms["firms_date"].notna().any():
        df_firms["year"] = df_firms["firms_date"].dt.year
        count_col = brightness_col or "firms_date"
        yearly = (
            df_firms.groupby("year", as_index=False)
            .agg(n_fires=(count_col, "count"))
            .sort_values("year")
        )

        chart_year = (
            alt.Chart(yearly)
            .mark_bar()
            .encode(
                x=alt.X("year:O", title="A√±o"),
                y=alt.Y("n_fires:Q", title="N¬∫ detecciones FIRMS"),
                tooltip=["year:O", "n_fires:Q"],
            )
            .properties(height=300)
        )
        st.altair_chart(chart_year, use_container_width=True)
    else:
        st.info("No hay fechas v√°lidas para construir la serie anual.")

# =========================================================
# 2) TAB COPERNICUS EFFIS
# =========================================================

@st.cache_data(show_spinner=True)
def load_copernicus_spain() -> gpd.GeoDataFrame:
    client = MongoClient(st.secrets["MONGO"]["URI"])
    db = client["incendios_espana"]
    col = db["copernicus_effis"]

    docs = list(col.find({}, {"_id": 0}))
    if not docs:
        return gpd.GeoDataFrame()

    geometries = [shape(d.pop("geometry")) for d in docs]

    return gpd.GeoDataFrame(
        docs,
        geometry=geometries,
        crs="EPSG:4326",
    )


with tab_cop:
    st.header("üî• Copernicus EFFIS ‚Äì Incendios forestales en Espa√±a")

    st.markdown(
        """
        Per√≠metros oficiales de incendios forestales (**Copernicus EFFIS**).

        - üá™üá∏ Dataset limitado a Espa√±a  
        - üó∫Ô∏è Pol√≠gonos reales  
        - ‚ö° Geometr√≠a simplificada
        """
    )

    

    # ---------- CARGA DATASET ----------
    gdf = load_copernicus_spain()

    if gdf.empty:
        st.warning("No hay datos Copernicus en MongoDB.")
    else:
        # resto del c√≥digo Copernicus

        st.success(f"Incendios cargados: **{len(gdf):,}**")
    
        # ---------- NORMALIZACI√ìN ----------
        gdf["YEAR"] = pd.to_numeric(gdf["YEAR"], errors="coerce")
        gdf["AREA_HA"] = pd.to_numeric(gdf["AREA_HA"], errors="coerce")
    
      # ---------- FILTROS ----------
        st.subheader("üîé Filtros (opcionales)")
        
        col1, col2 = st.columns(2)
        
        # Valores posibles
        years = sorted(gdf["YEAR"].dropna().unique())
        provs = sorted(gdf["PROVINCE"].dropna().unique())
        
        with col1:
            year_sel = st.selectbox(
                "A√±o",
                ["Todos"] + years,
                index=0,   # üëà por defecto TODOS
            )
        
        with col2:
            prov_sel = st.selectbox(
                "Provincia",
                ["Todas"] + provs,
                index=0,   # üëà por defecto TODAS
            )
        
        # ---------- APLICAR FILTROS SOLO SI CAMBIAN ----------
        gdf_filt = gdf.copy()
        
        if year_sel != "Todos":
            gdf_filt = gdf_filt[gdf_filt["YEAR"] == year_sel]
        
        if prov_sel != "Todas":
            gdf_filt = gdf_filt[gdf_filt["PROVINCE"] == prov_sel]
        
        st.caption(f"Incendios mostrados: **{len(gdf_filt):,}**")
            
        # ---------- M√âTRICAS ----------
        c1, c2 = st.columns(2)
    
        c1.metric(
            "√Årea total quemada (ha)",
            f"{gdf_filt['AREA_HA'].sum():,.0f}",
        )
    
        c2.metric(
            "N√∫mero de incendios",
            f"{len(gdf_filt):,}",
        )
    
        # ---------- MAPA ----------
        st.subheader("üó∫Ô∏è Mapa de per√≠metros quemados")
    
        if not gdf_filt.empty:
            gdf_map = gdf_filt.copy()
    
            for col in ["FIREDATE", "LASTUPDATE"]:
                if col in gdf_map.columns:
                    gdf_map[col] = gdf_map[col].astype(str)
    
            geojson = json.loads(gdf_map.to_json())
    
            layer = pdk.Layer(
                "GeoJsonLayer",
                geojson,
                pickable=True,
                filled=True,
                stroked=True,
                get_fill_color=[220, 20, 20, 140],
                get_line_color=[120, 0, 0, 220],
                line_width_min_pixels=1,
            )
    
            centroid = gdf_map.geometry.unary_union.centroid
    
            view_state = pdk.ViewState(
                latitude=centroid.y,
                longitude=centroid.x,
                zoom=6,
            )
    
            deck = pdk.Deck(
                layers=[layer],
                initial_view_state=view_state,
                map_style="https://basemaps.cartocdn.com/gl/positron-gl-style/style.json",
                tooltip={
                    "html": """
                    <b>Provincia:</b> {PROVINCE}<br/>
                    <b>A√±o:</b> {YEAR}<br/>
                    <b>√Årea quemada (ha):</b> {AREA_HA}<br/>
                    <b>Fecha:</b> {FIREDATE}
                    """
                },
            )
    
            st.pydeck_chart(deck, use_container_width=True)
    
        # ---------- TABLA ----------
        with st.expander("üìã Ver tabla de atributos"):
            st.dataframe(
                gdf_filt
                .drop(columns="geometry")
                .sort_values("AREA_HA", ascending=False),
                use_container_width=True,
            )
        
        


# =========================================================
# 3) TAB OPEN-METEO HIST√ìRICO
# =========================================================
@st.cache_data(show_spinner=True, ttl=0)
def load_openmeteo(path: str) -> pd.DataFrame:
    df_ = pd.read_csv(path)

    # --- limpiar nombres de columnas (BOM, espacios, etc.) ---
    df_.columns = (
        df_.columns
        .str.replace("\ufeff", "", regex=False)
        .str.strip()
    )

    # --- detectar columna de fecha ---
    if "time" in df_.columns:
        df_["date"] = pd.to_datetime(df_["time"], errors="coerce")
    elif "date" in df_.columns:
        df_["date"] = pd.to_datetime(df_["date"], errors="coerce")
    elif "datetime" in df_.columns:
        df_["date"] = pd.to_datetime(df_["datetime"], errors="coerce")
    elif "fecha" in df_.columns:
        df_["date"] = pd.to_datetime(df_["fecha"], errors="coerce")
    else:
        raise ValueError(
            f"No se encontr√≥ columna de fecha. Columnas disponibles: {list(df_.columns)}"
        )

    # --- renombrado est√°ndar ---
    df_ = df_.rename(
        columns={
            "temperature_2m_max": "meteo_temp_max",
            "temperature_2m_min": "meteo_temp_min",
            "relative_humidity_2m_min": "meteo_humidity_min",
            "windspeed_10m_max": "meteo_wind_max",
        }
    )

    return df_



OPENMETEO_CSV = (
    "https://github.com/aitorherran06/tfm/blob/main/data/openmeteo_historico.csv"
)


with tab_openmeteo:
    st.header("üå¶Ô∏è Open-Meteo ‚Äì Meteorolog√≠a hist√≥rica")

    st.markdown(
        """
Open-Meteo proporciona **series hist√≥ricas de meteorolog√≠a** a partir de coordenadas.  
En este dataset, los datos ya est√°n **agregados por provincia y d√≠a**, 
de forma que cada fila representa el clima diario de una provincia.
"""
    )

    # ---------- CARGA DATASET ----------
    try:
        df_met = load_openmeteo(OPENMETEO_CSV)

        st.success(f"Registros provincia‚Äìd√≠a: **{len(df_met):,}**")

        if df_met["date"].notna().any():
            min_date_met = df_met["date"].min()
            max_date_met = df_met["date"].max()
            st.caption(
                f"üóìÔ∏è Periodo disponible Open-Meteo: "
                f"**{min_date_met:%d/%m/%Y} ‚Äì {max_date_met:%d/%m/%Y}**"
            )
        else:
            st.caption("üóìÔ∏è Periodo disponible Open-Meteo: no hay fechas v√°lidas.")

    except Exception as e:
        st.error(f"‚ùå No se pudo cargar Open-Meteo: {e}")
        st.info("Revisa el CSV y el nombre de la columna de fecha.")
        st.stop()

    # ---------- EXPLICACI√ìN ----------
    with st.expander("‚ÑπÔ∏è ¬øQu√© significan las columnas de Open-Meteo?"):
        st.markdown(
            """
- **date**: d√≠a al que corresponde la observaci√≥n.  
- **provincia**: provincia asociada a las coordenadas.  
- **meteo_temp_max / meteo_temp_min**: temperatura m√°xima y m√≠nima diarias (¬∞C).  
- **meteo_humidity_min**: humedad relativa m√≠nima del d√≠a (%).  
- **meteo_wind_max**: velocidad m√°xima del viento (10 m).
"""
        )

    # ---------- TABLA ----------
    st.subheader("üìã Muestra de datos meteorol√≥gicos")

    cols_met_sample = [
        "date",
        "provincia",
        "meteo_temp_max",
        "meteo_temp_min",
        "meteo_humidity_min",
        "meteo_wind_max",
    ]
    cols_met_sample = [c for c in cols_met_sample if c in df_met.columns]

    st.dataframe(
        df_met[cols_met_sample].head(20),
        use_container_width=True,
    )

    # ---------- M√âTRICAS ----------
    st.subheader("üìä Indicadores b√°sicos")

    c1, c2, c3, c4 = st.columns(4)

    c1.metric(
        "Temp. m√°xima media",
        f"{df_met['meteo_temp_max'].mean():.1f} ¬∞C"
        if "meteo_temp_max" in df_met.columns
        else "N/D",
    )

    c2.metric(
        "Temp. m√≠nima media",
        f"{df_met['meteo_temp_min'].mean():.1f} ¬∞C"
        if "meteo_temp_min" in df_met.columns
        else "N/D",
    )

    c3.metric(
        "Humedad m√≠nima media",
        f"{df_met['meteo_humidity_min'].mean():.1f} %"
        if "meteo_humidity_min" in df_met.columns
        else "N/D",
    )

    c4.metric(
        "Viento m√°x. medio",
        f"{df_met['meteo_wind_max'].mean():.1f} km/h"
        if "meteo_wind_max" in df_met.columns
        else "N/D",
    )

    # ---------- SERIE MENSUAL ----------
    if "meteo_temp_max" in df_met.columns:
        st.subheader("üìà Temperatura m√°xima media por mes")

        df_met["month"] = df_met["date"].dt.month
        df_met["month_name"] = df_met["date"].dt.strftime("%b")

        monthly = (
            df_met.groupby(["month", "month_name"], as_index=False)
            .agg(temp_max_mean=("meteo_temp_max", "mean"))
            .sort_values("month")
        )

        chart_month = (
            alt.Chart(monthly)
            .mark_line(point=True)
            .encode(
                x=alt.X(
                    "month_name:N",
                    title="Mes",
                    sort=[
                        "Jan","Feb","Mar","Apr","May","Jun",
                        "Jul","Aug","Sep","Oct","Nov","Dec",
                    ],
                ),
                y=alt.Y(
                    "temp_max_mean:Q",
                    title="Temp. m√°xima media (¬∞C)",
                ),
            )
            .properties(height=300)
        )

        st.altair_chart(chart_month, use_container_width=True)



# =========================================================
# 4) TAB DATOS CRONJOBS (AEMET + FIRMS actualizado)
# =========================================================
with tab_cronjobs:
    st.header("‚è±Ô∏è Datos operativos generados por cronjobs")
    st.markdown(
        """
Esta secci√≥n resume los **datasets operativos** que se actualizan autom√°ticamente 
mediante _cronjobs_ y alimentan:

- el panel de **puntos calientes FIRMS recientes**, y  
- el panel de **predicci√≥n de riesgo a partir de AEMET**.
"""
    )

    # Conexi√≥n a Mongo
    try:
        mongo_uri = st.secrets["MONGO"]["URI"]
        client = MongoClient(mongo_uri)
        db = client["incendios_espana"]
    except Exception as e:
        db = None
        st.error(f"‚ùå No se pudo conectar a MongoDB (revisa `MONGO.URI`): {e}")

    if db is not None:
        # ---------- AEMET PREDICCIONES ----------
        st.subheader("üå¶Ô∏è Colecci√≥n `aemet_predicciones`")
        st.markdown(
            """
Contiene las **predicciones meteorol√≥gicas oficiales de AEMET** para los pr√≥ximos d√≠as
en cada provincia. Se genera diariamente mediante un proceso autom√°tico.
"""
        )

        col_aemet = db["aemet_predicciones"]
        count_aemet = col_aemet.count_documents({})
        st.write(f"üìÑ **Documentos totales:** {count_aemet}")

        # Rango de fechas AEMET
        try:
            doc_min_aemet = col_aemet.find_one(sort=[("fecha", 1)])
            doc_max_aemet = col_aemet.find_one(sort=[("fecha", -1)])
            if doc_min_aemet and doc_max_aemet:
                st.caption(
                    f"üóìÔ∏è Periodo disponible AEMET: "
                    f"**{doc_min_aemet.get('fecha')} ‚Äì {doc_max_aemet.get('fecha')}**"
                )
        except Exception:
            st.caption("üóìÔ∏è Periodo disponible AEMET: no se pudo calcular.")

        docs_aemet = list(col_aemet.find({}, {"_id": 0}).limit(20))

        filas = []
        for d in docs_aemet:
            temp = d.get("temperatura", {}) or {}
            hum = d.get("humedadRelativa", {}) or {}

            fila = {
                "provincia": d.get("provincia"),
                "fecha": d.get("fecha"),
                "tmax": temp.get("maxima"),
                "tmin": temp.get("minima"),
                "humedad_max": hum.get("maxima"),
                "humedad_min": hum.get("minima"),
                "uvMax": d.get("uvMax"),
            }
            filas.append(fila)

        if filas:
            df_aemet_sample = pd.DataFrame(filas)
            df_aemet_sample["fecha"] = pd.to_datetime(
                df_aemet_sample["fecha"], errors="coerce"
            )
            st.dataframe(df_aemet_sample, use_container_width=True)
        else:
            st.info("No hay documentos que mostrar en la muestra.")

        st.markdown("---")

        # ---------- FIRMS ACTUALIZADO ----------
        st.subheader("üî• Colecci√≥n `firms_actualizado`")
        st.markdown(
            """
Contiene las **detecciones FIRMS m√°s recientes** (√∫ltimos d√≠as) ya filtradas a Espa√±a.  
Se actualiza autom√°ticamente cada pocas horas mediante un _cronjob_.
"""
        )

        col_firms = db["firms_actualizado"]
        count_firms = col_firms.count_documents({})
        st.write(f"üìÑ **Documentos totales:** {count_firms}")

        # Rango de fechas FIRMS actualizado
        try:
            doc_min_firms = col_firms.find_one(
                {"fecha": {"$exists": True}}, sort=[("fecha", 1)]
            ) or col_firms.find_one(sort=[("datetime", 1)])

            doc_max_firms = col_firms.find_one(
                {"fecha": {"$exists": True}}, sort=[("fecha", -1)]
            ) or col_firms.find_one(sort=[("datetime", -1)])

            if doc_min_firms and doc_max_firms:
                vmin = doc_min_firms.get("fecha") or doc_min_firms.get("datetime")
                vmax = doc_max_firms.get("fecha") or doc_max_firms.get("datetime")
                st.caption(
                    f"üóìÔ∏è Periodo disponible FIRMS actualizado: **{vmin} ‚Äì {vmax}**"
                )
        except Exception:
            st.caption(
                "üóìÔ∏è Periodo disponible FIRMS actualizado: no se pudo calcular."
            )

        docs_firms = list(col_firms.find({}, {"_id": 0}).limit(20))

        if docs_firms:
            df_firms_sample = pd.DataFrame(docs_firms)
            st.dataframe(df_firms_sample, use_container_width=True)
        else:
            st.info("No hay documentos que mostrar en la muestra.")

    st.success("‚úÖ Informaci√≥n de cronjobs mostrada correctamente.")

# =========================================================
# 5) TAB EQUIVALENCIAS
# =========================================================
with tab_equiv:
    st.header("üîÑ Equivalencias de variables entre datasets")
    st.markdown(
        """
Esta secci√≥n muestra c√≥mo se corresponden las columnas entre distintas fuentes, 
lo que permite **unificar los datos** para an√°lisis y modelado.
"""
    )

    tab1, tab2 = st.tabs(["üõ∞Ô∏è FIRMS Hist√≥rico ‚Üî Actualizado", "üå¶Ô∏è AEMET ‚Üî Open-Meteo"])

    # -----------------------------------------------------
    #   TAB 1 : FIRMS
    # -----------------------------------------------------
    with tab1:
        st.header("üõ∞Ô∏è Equivalencias FIRMS ‚Äî Hist√≥rico ‚Üî Actualizado")
        st.markdown(
            """
Los ficheros de FIRMS antiguos y los m√°s recientes usan nombres de columnas distintos, 
aunque representan la misma informaci√≥n.  
Esta tabla resume las equivalencias usadas en el proyecto.
"""
        )

        equivalencias_firms = pd.DataFrame(
            {
                "FIRMS Hist√≥rico": [
                    "latitude",
                    "longitude",
                    "brightness",
                    "scan",
                    "track",
                    "acq_date",
                    "acq_time",
                    "satellite",
                    "instrument",
                ],
                "FIRMS Actualizado": [
                    "latitud",
                    "longitud",
                    "brightness",
                    "scan",
                    "track",
                    "fecha",
                    "hora",
                    "satellite",
                    "confianza",
                ],
                "Descripci√≥n": [
                    "Latitud del punto detectado",
                    "Longitud del punto detectado",
                    "Brillo (temperatura aparente del fuego, Kelvin)",
                    "Tama√±o del p√≠xel en direcci√≥n de escaneo",
                    "Tama√±o del p√≠xel en direcci√≥n de la trayectoria del sat√©lite",
                    "Fecha de adquisici√≥n",
                    "Hora de adquisici√≥n (UTC)",
                    "Sat√©lite utilizado",
                    "Nivel de confianza en la detecci√≥n",
                ],
            }
        )

        st.subheader("üìë Tabla comparativa FIRMS")
        st.dataframe(equivalencias_firms, use_container_width=True)

        st.info(
            """
‚û§ Los datasets contienen la misma informaci√≥n esencial, aunque con ajustes en nombres.  
‚û§ El campo **confianza** aparece en versiones actualizadas.  
"""
        )

        st.subheader("üîÑ Diccionario de renombrado FIRMS")
        diccionario_firms = {
            "latitude": "latitud",
            "longitude": "longitud",
            "acq_date": "fecha",
            "acq_time": "hora",
            "instrument": "instrumento",
        }
        st.code(diccionario_firms, language="python")
        st.caption("Aplicaci√≥n en pandas:")
        st.code("df.rename(columns=diccionario_firms, inplace=True)", language="python")

    # -----------------------------------------------------
    #   TAB 2 : AEMET ‚Üî Open-Meteo
    # -----------------------------------------------------
    with tab2:
        st.header("üå¶Ô∏è Equivalencias entre AEMET y Open-Meteo")
        st.markdown(
            """
AEMET y Open-Meteo describen fen√≥menos meteorol√≥gicos similares, 
pero con **nombres de columnas y estructuras distintas**.  
Esta tabla resume c√≥mo se han alineado en el proyecto.
"""
        )

        equivalencias = pd.DataFrame(
            {
                "AEMET": [
                    "fecha",
                    "municipio",
                    "provincia",
                    "tmax",
                    "tmin",
                    "humedad_max",
                    "humedad_min",
                    "viento",
                    "fuente",
                ],
                "Open-Meteo": [
                    "time",
                    None,
                    "provincia",
                    "temperature_2m_max",
                    "temperature_2m_min",
                    "relative_humidity_2m_max",
                    "relative_humidity_2m_min",
                    "windspeed_10m_max",
                    None,
                ],
                "Descripci√≥n": [
                    "Fecha de observaci√≥n o predicci√≥n",
                    "Municipio o estaci√≥n meteorol√≥gica",
                    "Provincia o regi√≥n administrativa",
                    "Temperatura m√°xima diaria (¬∞C)",
                    "Temperatura m√≠nima diaria (¬∞C)",
                    "Humedad relativa m√°xima (%)",
                    "Humedad relativa m√≠nima (%)",
                    "Velocidad m√°xima del viento",
                    "Fuente de los datos",
                ],
            }
        )

        st.subheader("üìë Tabla comparativa AEMET ‚Üî Open-Meteo")
        st.dataframe(equivalencias, use_container_width=True)

        st.info(
            """
‚û§ Open-Meteo usa coordenadas (lat/lon) en lugar de municipios.  
‚û§ Incluye m√°s variables como precipitaci√≥n total o radiaci√≥n solar.  
"""
        )

        st.subheader("üîÑ Diccionario de renombrado AEMET ‚Üí Open-Meteo")
        diccionario_renombrado = {
            "fecha": "time",
            "tmax": "temperature_2m_max",
            "tmin": "temperature_2m_min",
            "humedad_max": "relative_humidity_2m_max",
            "humedad_min": "relative_humidity_2m_min",
            "viento": "windspeed_10m_max",
            "provincia": "provincia",
        }
        st.code(diccionario_renombrado, language="python")
        st.caption("Aplicaci√≥n en pandas:")
        st.code("df.rename(columns=diccionario_renombrado, inplace=True)", language="python")

    st.success("‚úÖ Bloque de equivalencias cargado correctamente.")









